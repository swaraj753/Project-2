# -*- coding: utf-8 -*-
"""autolysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jn6Pj06E9Lq05lertdtrDAfYOvxqV1wE
"""

import os
import pandas as pd
import seaborn as sns
import matplotlib
matplotlib.use("Agg")  # Use a non-interactive backend for Colab
import matplotlib.pyplot as plt
import httpx
import chardet
from google.colab import files

# Constants
API_URL = "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
AIPROXY_TOKEN = "eyJhbGciOiJIUzI1NiJ9.eyJlbWFpbCI6IjIzZjEwMDEyNDVAZHMuc3R1ZHkuaWl0bS5hYy5pbiJ9.1PfKzANZvTRruGX0rwDXoG7trl08X6tPC3028G3ZqhY"  # Replace with your AIPROXY_TOKEN

def upload_files():
    """Upload files in Colab."""
    uploaded = files.upload()
    return uploaded

def load_data(file_path):
    """Load CSV data with encoding detection."""
    with open(file_path, 'rb') as f:
        result = chardet.detect(f.read())
    encoding = result['encoding']
    return pd.read_csv(file_path, encoding=encoding)

def analyze_data(df):
    """Perform basic data analysis."""
    numeric_df = df.select_dtypes(include=['number'])  # Select only numeric columns
    analysis = {
        'summary': df.describe(include='all').to_dict(),
        'missing_values': df.isnull().sum().to_dict(),
        'correlation': numeric_df.corr().to_dict()  # Compute correlation only on numeric columns
    }
    return analysis

def visualize_data(df, file_name):
    """Generate and save visualizations."""
    sns.set(style="whitegrid")
    numeric_columns = df.select_dtypes(include=['number']).columns
    for column in numeric_columns:
        plt.figure()
        sns.histplot(df[column].dropna(), kde=True)
        plt.title(f'Distribution of {column}')
        plt.savefig(f'{file_name}_{column}_distribution.png')
        plt.close()

def generate_narrative(analysis):
    """Generate narrative using LLM."""
    headers = {
        'Authorization': f'Bearer {AIPROXY_TOKEN}',
        'Content-Type': 'application/json'
    }
    prompt = f"Provide a detailed analysis based on the following data summary: {analysis}"
    data = {
        "model": "gpt-4o-mini",
        "messages": [{"role": "user", "content": prompt}]
    }
    try:
        response = httpx.post(API_URL, headers=headers, json=data, timeout=30.0)
        response.raise_for_status()
        return response.json()['choices'][0]['message']['content']
    except httpx.HTTPStatusError as e:
        print(f"HTTP error occurred: {e}")
    except httpx.RequestError as e:
        print(f"Request error occurred: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
    return "Narrative generation failed due to an error."

def process_file(file_path):
    """Process a single CSV file."""
    df = load_data(file_path)
    analysis = analyze_data(df)
    visualize_data(df, os.path.splitext(os.path.basename(file_path))[0])  # Save with the base filename
    narrative = generate_narrative(analysis)
    report_filename = f'{os.path.splitext(os.path.basename(file_path))[0]}_README.md'
    with open(report_filename, 'w') as f:
        f.write(narrative)
    # Provide the user with the option to download the generated files
    files.download(report_filename)
    # Download all saved plots
    for column in df.select_dtypes(include=['number']).columns:
        plot_filename = f'{os.path.splitext(os.path.basename(file_path))[0]}_{column}_distribution.png'
        files.download(plot_filename)

def main():
    # Upload files in Colab
    uploaded_files = upload_files()

    # Process each uploaded file
    for file_name in uploaded_files.keys():
        print(f"Processing {file_name}...")
        if os.path.exists(file_name):
            process_file(file_name)
            print(f"Finished processing {file_name}. Results saved.")
        else:
            print(f"File {file_name} not found. Skipping.")

if __name__ == "__main__":
    main()

